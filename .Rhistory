url <- "https://app.predictiveanalytics.co.ke/#/data/hr_comma_sep.csv"
dest_file <- "data/hr_comma_sep.csv"
download.file(url, destfile = dest_file)
hr <- load("rda/hr_comma_sep.rda")
hr <- read.csv("data/hr_comma_sep.csv")
save(hr,file = "rda/hr_comma_sep.rda")
str(hr)
colnames(hr)
hr <- load("rda/hr_comma_sep.rda")
str(hr)
colnames(hr)
#data type conversion
hr$department=as.factor(hr$department)
hr
load("rda/hr_comma_sep.rda")
#hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
colnames(hr)
hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
colnames(hr)
hr<-read.csv("hr_comma_sep.rda")
hr<-read.csv("rda/hr_comma_sep.rda")
str(hr)
hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
colnames(hr)
hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
View(hr)
hr <- load("rda/hr_comma_sep.rda")
str(hr)
hr
hr <- load("data/hr_comma_sep.csv")
str(hr)
hr <- load("rda/hr_comma_sep.rda")
hr
str(hr)
colnames(hr)
load("rda/hr_comma_sep.rda")
hr<-read.csv("rda/hr_comma_sep.rda")
hr<-read.csv("data/hr_comma_sep.csv")
hr
hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
View(hr)
hr<-read.csv("data/hr_comma_sep.csv")
str(hr)
colnames(hr)
hr <- read.csv("data/hr_comma_sep.csv")
save(hr,file = "rda/hr_comma_sep.rda")
hr
str(hr)
load("C:/Users/user/MyProjects/hr-module/rda/hr_comma_sep.rda")
View(hr)
url <- "https://app.predictiveanalytics.co.ke/#/data/all"
dest_file <- "data/hr_comma_sep.csv"
download.file(url, destfile = dest_file)
load("C:/Users/user/MyProjects/hr-module/rda/hr_comma_sep.rda")
View(hr)
hr<-read.csv("data/hr_comma_sep.csv")
str(hr)
colnames(hr)
hr<-read.csv("data/hr_comma_sep.csv")
#hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
colnames(hr)
#data type conversion
hr$department=as.factor(hr$department)
hr$salary=as.factor(hr$salary)
str(hr)
hr<-read.csv(file.choose(),stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
colnames(hr)
#data type conversion
hr$department=as.factor(hr$department)
hr$salary=as.factor(hr$salary)
str(hr)
#hr<-read.csv("data/hr_comma_sep.csv")
hr<-read.csv(data/hr_comma_sep.csv,stringsAsFactors = F,na.strings = c("","NA",""))
#hr<-read.csv("data/hr_comma_sep.csv")
hr<-read.csv("data/hr_comma_sep.csv",stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
colnames(hr)
#data type conversion
hr$department=as.factor(hr$department)
hr$salary=as.factor(hr$salary)
str(hr)
#Exporatory Data Analysis
unlist(lapply(hr,class))
ftable<-table(hr$department,hr$salary)
ftable
mosaicplot(ftable,main="Distribution of Departments by their Salary",color=TRUE)
chisq.test(ftable)
ggsave("figs/mosaicplot.png")
library(ggplot2)
ggsave("figs/mosaicplot.png")
chisq.test(ftable)
hr$left=as.factor(hr$left)
str(hr)
# insample distribution
logit_model<-glm(left~satisfaction_level+last_evaluation+number_project+
Work_accident+promotion_last_5years+average_montly_hours+
time_spend_company,data = hr, family = "binomial")
summary(logit_model)
#predict churn
hr$left_pred<-predict(logit_model,data=hr,type="response")
#changing the probabilities into class (0 or 1)
hr$left_pred<-ifelse(hr$left_pred>0.5,1,0)
hr$left_pred=as.factor(hr$left_pred)
str(hr)
#confusion matrix
table(hr$left,hr$left_pred)
misClassError<-mean(hr$left_pred!=hr$left)
print(paste('Accuracy=',1-misClassError))
#Splitting the data in train and test data
#install.packages('caTools')
library(caTools)
set.seed(123)
split<-sample.split(hr,SplitRatio=0.75)
split
train<-subset(hr,split=="TRUE")
test<-subset(hr,split=="FALSE")
str(train)
str(test)
logit_model_tr<-glm(left~satisfaction_level+last_evaluation+number_project+
Work_accident+promotion_last_5years+average_montly_hours+
time_spend_company,data = train, family = "binomial")
logit_model_tr
predicted.result<-predict(logit_model_tr,test,type = "response")
predicted.result
predicted.result<-ifelse(predicted.result>0.5,1,0)
predicted.result
#Evaluating model accuracy using confusion matrix
table(test$left,predicted.result)
misClassError<-mean(predicted.result!=test$left)
print(paste('Accuracy=',1-misClassError))
#model evaluation using a confusion matrix
library(caret)
confusionMatrix(table(test$left,predicted.result))
#ROC-AUC CURVE
library(ROCR)
ROCRpred<-prediction(predicted.result,test$left)
ROCRperf<-performance(ROCRpred,measure="tpr",x.measure="fpr")
plot(ROCRperf)
plot(ROCRperf,colorize=TRUE)
plot(ROCRperf,colorize=TRUE,print.cutoffs.at=seq(0.1,by=0.1))
plot(ROCRperf,colorize=TRUE,print.cutoffs.at=seq(0.1,by=0.1),main = "ROC CURVE")
abline(a=0,b=1)
ggsave("figs/ROC-CURVEplot.png")
auc<-performance(ROCRpred,measure="auc")
auc<-auc@y.values[[1]]
auc
auc<-round(auc,4)
legend(.5,.4,auc,title="AUC",cex=1)
ggsave("figs/AUCplot.png")
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_chunk$set(echo = TRUE)
View(logit_model)
install.packages("rmarkdown")
chisq.test(ftable)
hr<-read.csv("data/hr_comma_sep.csv",stringsAsFactors = F,na.strings = c("","NA",""))
str(hr)
colnames(hr)
#data type conversion
hr$department=as.factor(hr$department)
hr$salary=as.factor(hr$salary)
str(hr)
#Exporatory Data Analysis
unlist(lapply(hr,class))
ftable<-table(hr$department,hr$salary)
ftable
mosaicplot(ftable,main="Distribution of Departments by their Salary",color=TRUE)
chisq.test(ftable)
chisq.test(ftable$p-value)
chisq.test(ftable$p-value)
chisq.test(ftable$"p-value")
chisq.test(p-value)
chisq.test(ftable,p-value)
chisq.test(ftable,p-value)
hr$left=as.factor(hr$left)
str(hr)
# insample distribution
logit_model<-glm(left~satisfaction_level+last_evaluation+number_project+
Work_accident+promotion_last_5years+average_montly_hours+
time_spend_company,data = hr, family = "binomial")
summary(logit_model)
#predict churn
hr$left_pred<-predict(logit_model,data=hr,type="response")
#changing the probabilities into class (0 or 1)
hr$left_pred<-ifelse(hr$left_pred>0.5,1,0)
hr$left_pred=as.factor(hr$left_pred)
str(hr)
#confusion matrix
table(hr$left,hr$left_pred)
misClassError<-mean(hr$left_pred!=hr$left)
print(paste('Accuracy=',1-misClassError))
#Splitting the data in train and test data
#install.packages('caTools')
library(caTools)
set.seed(123)
split<-sample.split(hr,SplitRatio=0.75)
split
train<-subset(hr,split=="TRUE")
test<-subset(hr,split=="FALSE")
str(train)
str(test)
logit_model_tr<-glm(left~satisfaction_level+last_evaluation+number_project+
Work_accident+promotion_last_5years+average_montly_hours+
time_spend_company,data = train, family = "binomial")
logit_model_tr
predicted.result<-predict(logit_model_tr,test,type = "response")
predicted.result
predicted.result<-ifelse(predicted.result>0.5,1,0)
predicted.result
#Evaluating model accuracy using confusion matrix
table(test$left,predicted.result)
misClassError<-mean(predicted.result!=test$left)
print(paste('Accuracy=',1-misClassError))
#model evaluation using a confusion matrix
library(caret)
confusionMatrix(table(test$left,predicted.result))
#ROC-AUC CURVE
library(ROCR)
ROCRpred<-prediction(predicted.result,test$left)
ROCRperf<-performance(ROCRpred,measure="tpr",x.measure="fpr")
plot(ROCRperf)
plot(ROCRperf,colorize=TRUE)
plot(ROCRperf,colorize=TRUE,print.cutoffs.at=seq(0.1,by=0.1))
plot(ROCRperf,colorize=TRUE,print.cutoffs.at=seq(0.1,by=0.1),main = "ROC CURVE")
abline(a=0,b=1)
ggsave("figs/ROC-CURVEplot.png")
auc<-performance(ROCRpred,measure="auc")
auc<-auc@y.values[[1]]
auc
auc<-round(auc,4)
legend(.5,.4,auc,title="AUC",cex=1)
ggsave("figs/AUCplot.png")
mosaicplot(ftable,main="Distribution of Departments by their Salary",color=TRUE,
theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)))
mosaicplot(ftable,main="Distribution of Departments by their Salary",color=TRUE,
(axis.text.x = element_text(angle = 90, hjust = 1, vjust = 0.5)))
mosaicplot(ftable,main="Distribution of Departments by their Salary",color=TRUE)
mosaicplot(ftable,main="Distribution of Departments by their Salary",color=TRUE, bw=1)
ggsave("figs/AUCplot.png")
hr<-read.csv("data/hr_comma_sep.csv")
str(hr)
hr$left=as.factor(hr$left)
str(hr)
unlist(lapply(hr,class))
library(caTools)
set.seed(1234)
split<-sample.split(hr,SplitRatio = 0.75)
split
train<-subset(hr,split=="TRUE")
test<-subset(hr,split=="FALSE")
str(train)
str(test)
## Training model with rpart function
library("rpart") ##recursive partioning
library("rpart.plot")
DecTreeModel<-rpart(left~.,data=train,method = "class")
summary(DecTreeModel)
printcp(DecTreeModel)
plotcp(DecTreeModel)
rpart.plot(DecTreeModel)
## Predicting test using trained model
test$left_Pred<-predict(DecTreeModel,newdata = test,type = "class")
#Evaluating model accuracy using confusion matrix
table(test$left,test$left_Pred)
misClassError<-mean(test$left_Pred!=test$left)
print(paste('Accuracy=',1-misClassError))
library(caret)
confusionMatrix(table(test$left,test$left_Pred))
cm(table(test$left,test$left_Pred))
##Tree pruning
#find the value of CP for which the cross validation error is minimum
min(DecTreeModel$cptable[,"xerror"])
which.min(DecTreeModel$cptable[,"xerror"])
cpmin<-DecTreeModel$cptable[8,"CP"]
cpmin
##prune the tree by setting the cp parameter = cpmin
DecTreeModelPruned=prune(DecTreeModel,cp=cpmin)
rpart.plot(DecTreeModelPruned)
printcp(DecTreeModelPruned)
plotcp(DecTreeModelPruned)
DecTreeModel<-rpart(left~.,data=train,method = "class")
summary(DecTreeModel)
printcp(DecTreeModel)
plotcp(DecTreeModel)
rpart.plot(DecTreeModel)
## Predicting test using trained model
test$left_Pred<-predict(DecTreeModel,newdata = test,type = "class")
#Evaluating model accuracy using confusion matrix
table(test$left,test$left_Pred)
misClassError<-mean(test$left_Pred!=test$left)
print(paste('Accuracy=',1-misClassError))
library(caret)
confusionMatrix(table(test$left,test$left_Pred))
##Tree pruning
#find the value of CP for which the cross validation error is minimum
min(DecTreeModel$cptable[,"xerror"])
which.min(DecTreeModel$cptable[,"xerror"])
cpmin<-DecTreeModel$cptable[8,"CP"]
cpmin
##prune the tree by setting the cp parameter = cpmin
DecTreeModelPruned=prune(DecTreeModel,cp=cpmin)
rpart.plot(DecTreeModelPruned)
printcp(DecTreeModelPruned)
plotcp(DecTreeModelPruned)
DecTreeModel<-rpart(left~.,data=train,method = "class")
DecTreeModel
rpart.plot(DecTreeModel)
summary(DecTreeModel)
printcp(DecTreeModel)
plotcp(DecTreeModel)
## Step 3: Predicting test based on trained model
test$left_Pred<-predict(DecTreeModel,newdata = test,type = "class")
## Step 4: Evaluating model accuracy using confusion matrix
table(test$left,test$left_Pred)
library(caret)
confusionMatrix(table(test$left,test$left_Pred))
##Tree pruning
#find the value of CP for which the cross validation error is minimum
min(DecTreeModel$cptable[,"xerror"])
which.min(DecTreeModel$cptable[,"xerror"])
cpmin<-DecTreeModel$cptable[8,"CP"]
cpmin
##prune the tree by setting the cp parameter = cpmin
DecTreeModelPruned=prune(DecTreeModel,cp=cpmin)
rpart.plot(DecTreeModelPruned)
DecTreeModel$cptable
##Tree pruning
#find the value of CP for which the cross validation error is minimum
min(DecTreeModel$cptable[,"xerror"])
which.min(DecTreeModel$cptable[,"xerror"])
cpmin<-DecTreeModel$cptable[8,"CP"]
cpmin
##prune the tree by setting the cp parameter = cpmin
DecTreeModelPruned=prune(DecTreeModel,cp=cpmin)
rpart.plot(DecTreeModelPruned)
## Step 2: Training model with logistics regression using glm function
library("rpart") ##recursive partioning
library("rpart.plot")
DecTreeModel<-rpart(left~.,data=train,method = "class")
DecTreeModel
rpart.plot(DecTreeModel)
rpart.plot(DecTreeModel)
rpart.plot(DecTreeModel)
summary(DecTreeModel)
printcp(DecTreeModel)
plotcp(DecTreeModel)
## Step 3: Predicting test based on trained model
test$left_Pred<-predict(DecTreeModel,newdata = test,type = "class")
## Step 4: Evaluating model accuracy using confusion matrix
table(test$left,test$left_Pred)
library(caret)
confusionMatrix(table(test$left,test$left_Pred))
##Tree pruning
#find the value of CP for which the cross validation error is minimum
min(DecTreeModel$cptable[,"xerror"])
which.min(DecTreeModel$cptable[,"xerror"])
cpmin<-DecTreeModel$cptable[8,"CP"]
cpmin
hr<-read.csv("data/hr_comma_sep.csv")
hr$left=as.factor(hr$left)
#Step 1:Split data in train and test data
library(caTools)
set.seed(123)
split <- sample.split(hr, SplitRatio = 0.75)
split
training_set = subset(hr, split == TRUE)
test_set = subset(hr, split == FALSE)
#Step 2: Fitting Random Forest Classifier into the Training set
# install.packages('randomForest')
library(randomForest)
classifier <- randomForest(x = training_set[-7],
y = training_set$left,
ntree = 500)
bestmtry<-tuneRF(training_set,training_set$left,stepFactor = 1.2,improve = 0.01,trace = T,plot = T)
#Step 3: Predicting test set data by train set model
y_pred = predict(classifier, newdata = test_set[-7])
#Step 4: Model Evaluation by  checking accuracy using a confusion matrix
table(test_set$left,y_pred)
misClassError<-mean(test_set$left!=y_pred)
print(paste('Accuracy=',1-misClassError))
library(caret)
confusionMatrix(cm)
#Step 4: Model Evaluation by  checking accuracy using a confusion matrix
cm <- table(test_set$left,y_pred)
confusionMatrix(cm)
plot(classifier)
importance(classifier)
varImpPlot(classifier)
install.packages("TeXCheckR")
install.packages("pdfLaTeX")
